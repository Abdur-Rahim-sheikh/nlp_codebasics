{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dbd2b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7366e79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Strange\n",
      "loves\n",
      "pav\n",
      "bhaji\n",
      "of\n",
      "mumbai\n",
      "as\n",
      "it\n",
      "costs\n",
      "only\n",
      "2\n",
      "$\n",
      "per\n",
      "plate\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate.')\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c764ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "# firstlanguage.in it helps \n",
    "\n",
    "doc2 = nlp('\"Let\\'s go to N.Y.!\"')\n",
    "for word in doc2:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85f0490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007bb9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony ==> \n",
      "\tindex:  0 \n",
      "\tis_alpha:  True \n",
      "\tis_punct:  False \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n",
      "gave ==> \n",
      "\tindex:  1 \n",
      "\tis_alpha:  True \n",
      "\tis_punct:  False \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n",
      "two ==> \n",
      "\tindex:  2 \n",
      "\tis_alpha:  True \n",
      "\tis_punct:  False \n",
      "\tlike_num:  True \n",
      "\tis_currency:  False\n",
      "$ ==> \n",
      "\tindex:  3 \n",
      "\tis_alpha:  False \n",
      "\tis_punct:  False \n",
      "\tlike_num:  False \n",
      "\tis_currency:  True\n",
      "to ==> \n",
      "\tindex:  4 \n",
      "\tis_alpha:  True \n",
      "\tis_punct:  False \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n",
      "Peter ==> \n",
      "\tindex:  5 \n",
      "\tis_alpha:  True \n",
      "\tis_punct:  False \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n",
      ". ==> \n",
      "\tindex:  6 \n",
      "\tis_alpha:  False \n",
      "\tis_punct:  True \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp('Tony gave two $ to Peter.')\n",
    "\n",
    "\n",
    "for token in doc3:\n",
    "    print(token, \"==>\",\n",
    "         \"\\n\\tindex: \",token.i,\n",
    "         \"\\n\\tis_alpha: \",token.is_alpha,\n",
    "         \"\\n\\tis_punct: \",token.is_punct,\n",
    "         \"\\n\\tlike_num: \", token.like_num,\n",
    "         \"\\n\\tis_currency: \", token.is_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a57fc9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dayton high school, 8th grade students information\\n',\n",
       " '==================================================\\n',\n",
       " '\\n',\n",
       " 'Name\\tbirth day   \\temail\\n',\n",
       " '-----\\t------------\\t------\\n',\n",
       " 'Virat   5 June, 1882    virat@kohli.com\\n',\n",
       " 'Maria\\t12 April, 2001  maria@sharapova.com\\n',\n",
       " 'Serena  24 June, 1998   serena@williams.com \\n',\n",
       " 'Joe      1 May, 1997    joe@root.com\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('students.txt') as f:\n",
    "    text = f.readlines()\n",
    "    \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fec35ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dayton high school, 8th grade students information\\n ==================================================\\n \\n Name\\tbirth day   \\temail\\n -----\\t------------\\t------\\n Virat   5 June, 1882    virat@kohli.com\\n Maria\\t12 April, 2001  maria@sharapova.com\\n Serena  24 June, 1998   serena@williams.com \\n Joe      1 May, 1997    joe@root.com\\n \\n \\n \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26543cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virat@kohli.com',\n",
       " 'maria@sharapova.com',\n",
       " 'serena@williams.com',\n",
       " 'joe@root.com']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5 = nlp(text)\n",
    "emails = []\n",
    "for token in doc5:\n",
    "    if token.like_email:\n",
    "        emails.append(token.text)\n",
    "        \n",
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce12019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "আবির ==> \n",
      "\tindex:  0 \n",
      "\tis_alpha:  False \n",
      "\tis_punct:  False \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n",
      "বন্ধু ==> \n",
      "\tindex:  1 \n",
      "\tis_alpha:  False \n",
      "\tis_punct:  False \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n",
      "! ==> \n",
      "\tindex:  2 \n",
      "\tis_alpha:  False \n",
      "\tis_punct:  True \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n",
      "আমার ==> \n",
      "\tindex:  3 \n",
      "\tis_alpha:  False \n",
      "\tis_punct:  False \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n",
      "সেই ==> \n",
      "\tindex:  4 \n",
      "\tis_alpha:  False \n",
      "\tis_punct:  False \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n",
      "৫০০ ==> \n",
      "\tindex:  5 \n",
      "\tis_alpha:  False \n",
      "\tis_punct:  False \n",
      "\tlike_num:  True \n",
      "\tis_currency:  False\n",
      "টাকাটা ==> \n",
      "\tindex:  6 \n",
      "\tis_alpha:  False \n",
      "\tis_punct:  False \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n",
      "লাগবে ==> \n",
      "\tindex:  7 \n",
      "\tis_alpha:  False \n",
      "\tis_punct:  False \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n",
      "। ==> \n",
      "\tindex:  8 \n",
      "\tis_alpha:  False \n",
      "\tis_punct:  True \n",
      "\tlike_num:  False \n",
      "\tis_currency:  False\n"
     ]
    }
   ],
   "source": [
    "nlp_bn = spacy.blank('bn')\n",
    "\n",
    "doc6 = nlp_bn('আবির বন্ধু! আমার সেই ৫০০ টাকাটা লাগবে।')\n",
    "\n",
    "for token in doc6:\n",
    "    print(token, \"==>\",\n",
    "         \"\\n\\tindex: \",token.i,\n",
    "         \"\\n\\tis_alpha: \",token.is_alpha,\n",
    "         \"\\n\\tis_punct: \",token.is_punct,\n",
    "         \"\\n\\tlike_num: \", token.like_num,\n",
    "         \"\\n\\tis_currency: \", token.is_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d5d8bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc6[0])\n",
    "doc6[0].is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e582d3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc7 = nlp('gimme double cheese extra large healthy pizza')\n",
    "\n",
    "tokens = [token.text for token in doc7]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6313371a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "# cannot modify the text\n",
    "nlp.tokenizer.add_special_case(\"gimme\",[\n",
    "    {ORTH: 'gim'},\n",
    "    {ORTH: 'me'}\n",
    "])\n",
    "doc8 = nlp('gimme double cheese extra large healthy pizza')\n",
    "tokens = [token.text for token in doc8]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0f04eb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m doc8 \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sentence)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_env/lib/python3.10/site-packages/spacy/tokens/doc.pyx:890\u001b[0m, in \u001b[0;36msents\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "doc8 = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16c52b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencizer']\n",
      "Dr. Strange loves pav bhaji of mumbai.\n",
      "Hulk loves chat of delhi\n"
     ]
    }
   ],
   "source": [
    "# nlp.add_pipe('sentencizer')\n",
    "print(nlp.pipe_names)\n",
    "doc9 = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "\n",
    "\n",
    "for sentence in doc9.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcb64cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencizer']\n",
      "Dr.\n",
      "Strange loves pav bhaji of mumbai.\n",
      "Hulk loves chat of delhi\n"
     ]
    }
   ],
   "source": [
    "nlp_bn.add_pipe('sentencizer')\n",
    "print(nlp_bn.pipe_names)\n",
    "doc9 = nlp_bn(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "\n",
    "\n",
    "for sentence in doc9.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54369ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
